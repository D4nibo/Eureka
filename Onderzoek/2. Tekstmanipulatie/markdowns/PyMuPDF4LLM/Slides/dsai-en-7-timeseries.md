# **Module 7. Time series analysis**
## **Data Science**

**Sabine De Vreese** **Lieven Smits** **Pieter Van Der Helst** **Bert Van Vreckem**

**2024â€“2025**


1/39


-----

# **Contents**

Time series and predictions

Time series models

Mathematical model

General

Estimating the parameters

Moving average

Simple moving average
Weighted moving average
Double exponential smoothing
Forecasting
Triple exponential smoothing

2/39


-----

# **Learning goals**

   - Concepts, time series models

   - Moving average

   - Exponential smoothing
## **Remark**

You should not memorize the formulas in this module, but you should
understand them!

3/39


-----

# **Time series and predictions**


4/39


-----

# **Time series and predictions**





- Monthly demand for milk

- Annual intake of students at HOGENT

- Price of a share or bond on the stock exchange (hourly, daily, â€¦)

- Number of HTTP requests per second for a website

- Evolution of disk usage on a backup server


5/39


-----

# **Time series and predictions**

May decisions in business operations depend on a forecast of some
quantity

   - General development of future plans (investments, capacity â€¦)

   - Budget planning to avoid shortcomings (operating budget,
marketing budget â€¦)

   - Procurement planning (e.g. storage capacity)

   - Support for financial objectives

   - Avoid uncertainty

6/39


-----

# **Time series and predictions**

Time series are a **statistical** problem: observations vary with time

Figure: Number of heavily wounded in car accidents in Flanders.


-----

# **Time series components**

   - Level

   - Trend

   - Seasonal fluctuations

   - Cyclic patterns

   - Random noise (residuals)

8/39


-----

# **Time series decomposition**

9/39


-----

# **Time series models**


10/39


-----

# **Mathematical model time series**

**The simplest model:**

ğ‘‹ ğ‘¡ = ğ‘+ ğœ€ ğ‘¡ (1)

  - ğ‘‹ ğ‘¡ : estimate for time series, at time ğ‘¡

   - ğ‘: the level (a constant), based on **observations** ğ‘¥ ğ‘¡

  - ğœ€ ğ‘¡ : random **noise** . We assume that ğœ€ ğ‘¡ âˆ¼ğ‘ğ‘œğ‘Ÿ(ğœ‡= 0; ğœ)

11/39


-----

# **Mathematical model time series**

We could also assume that there is a linear relationship:

ğ‘‹ ğ‘¡ = ğ‘ 0 + ğ‘ 1 ğ‘¡+ ğœ€ ğ‘¡ (2)

with **level** ğ‘ 0 and **trend** ğ‘ 1 .

Equation 1 and 2 are special cases of the **polynomial** case:

ğ‘‹ ğ‘¡ = ğ‘ 0 + ğ‘ 1 ğ‘¡+ ğ‘ 2 ğ‘¡ [2] + â‹¯+ ğ‘ ğ‘› ğ‘¡ [ğ‘›] + ğœ€ ğ‘¡ (3)

12/39


-----

# **General expression time series**

ğ‘‹ ğ‘¡ = ğ‘“(ğ‘ 0, ğ‘ 1, ğ‘ 2, â€¦, ğ‘ ğ‘›, ğ‘¡) + ğœ€ ğ‘¡ (4)

We make these assumptions:

   - We consider two components of variability:

     - the mean of the predictions changes with time

     - the variations to this mean vary randomly

   - The residuals of the model (ğ‘‹ ğ‘¡ âˆ’ğ‘¥ ğ‘¡ ) have a constant variance in time
( **homoscedastic** )

13/39


-----

# **Estimating the parameters**

Make **predictions** based on the time series model:

1. select the most suitable model

2. estimation for parameters ğ‘ ğ‘– (ğ‘–âˆ¶1, â€¦, ğ‘›) based on observations

The estimations Ì‚ğ‘ ğ‘– are selected so that they approximate the observed
values as close as possible.

14/39


-----

# **Example**

**Number of heavily wounded in car accidents in Flanders**

15/39


-----

# **Example: parameter estimation**

   - We select the constant model of Equation 1

   - You choose which observations you use to determine ğ‘ [Ì‚], e.g.

1

     - First 70 observations: ğ‘= [Ì‚] 70 [âˆ‘] ğ‘¡=1 [70] [ğ‘¥] ğ‘¡ [= 346.4]

1

     - Last 50 observations: ğ‘= [Ì‚] 50 [âˆ‘] ğ‘¡=47 [96] [ğ‘¥] ğ‘¡ [= 290.68]

16/39


-----

# **Example: parameter estimation**

If we want to model the observations with a linear function
ğ‘‹ ğ‘¡ = ğ‘ 0 + ğ‘ 1 ğ‘¡+ ğœ€ ğ‘¡, then we can use linear regression!

17/39


-----

# **Moving average**


18/39


-----

# **Moving average**





- Notation: SMA

- Hide short-term fluctuations and show long-term trends

- Parameter ğ‘š is the time window


ğ‘†ğ‘€ğ´(ğ‘¡) =


ğ‘¡
âˆ‘

ğ‘–=ğ‘˜


ğ‘¥
ğ‘–
(5)
ğ‘š


with ğ‘˜= ğ‘¡âˆ’ğ‘š+ 1.


19/39


-----

# **Example**

20/39


-----

# **Example: â€œGolden crossâ€**

Moving averages are used in the **technical analysis** of stock prices to
discover trends:


-----

# **Weighted moving average**

   - For ğ‘†ğ‘€ğ´, the weights of the observations are equal

   - For a weighted moving average (ğ‘Šğ‘€ğ´), more recent observations
gain relatively more weight

   - A specific form of this is single exponential smoothing or the
**exponential moving average** (EMA):

ğ‘‹ ğ‘¡ = ğ›¼ğ‘¥ ğ‘¡âˆ’1 + (1 âˆ’ğ›¼)ğ‘‹ ğ‘¡âˆ’1 (6)

with ğ›¼ the smoothing constant (0 < ğ›¼< 1), and ğ‘¡â‰¥3

22/39


-----

# **Exponential smoothing**

Equation 6 is only valid from ğ‘¡= 3. Hence, we need to choose a suitable
value for ğ‘‹
2 ourselves. There are several options:

  - ğ‘‹
2 = ğ‘¥ 1

  - ğ‘‹ [1]
2 = ğ‘š [âˆ‘] ğ‘–=1 [ğ‘š] [ğ‘¥] ğ‘– [(so the mean of the first][ ğ‘š] [observations)]

   - make ğ‘‹
2 equal to a specific objective

   - â€¦

23/39


-----

# **Exponential Smoothing**

**Example of calculation (** ğ›¼= 0.1 **)**

ğ‘¡ 1 2 3 4 â€¦

ğ‘¥ 8 10 11 13 â€¦
ğ‘¡

ğ‘¡

ğ‘‹ 1 = undefined

ğ‘‹ = ğ‘¥
2 1

ğ‘‹ = 0.1 Ã— 10 + 0.9 Ã— 8 = 8.2
3

ğ‘‹ = 0.1 Ã— 13 + 0.9 Ã— 8.2 = 8.68
4

24/39


-----

# **Why â€œ exponential â€?**

ğ‘‹ ğ‘¡ = ğ›¼ğ‘¥ ğ‘¡âˆ’1 + (1 âˆ’ğ›¼)ğ‘‹ ğ‘¡âˆ’1
= ğ›¼ğ‘¥ ğ‘¡âˆ’1 + (1 âˆ’ğ›¼) [ğ›¼ğ‘¥ ğ‘¡âˆ’2 + (1 âˆ’ğ›¼)ğ‘‹ ğ‘¡âˆ’2 ]

= ğ›¼ğ‘¥ ğ‘¡âˆ’1 + ğ›¼(1 âˆ’ğ›¼)ğ‘¥ ğ‘¡âˆ’2 + (1 âˆ’ğ›¼) [2] ğ‘‹ ğ‘¡âˆ’2
or in general:


= ğ›¼


ğ‘¡âˆ’2
âˆ‘(1 âˆ’ğ›¼) [ğ‘–âˆ’1] ğ‘¥ ğ‘¡âˆ’ğ‘– + (1 âˆ’ğ›¼) [ğ‘¡âˆ’ğ‘–] ğ‘‹ ğ‘¡âˆ’ğ‘–, ğ‘¡â‰¥2
ğ‘–=1


In other words: older observations have an exponentially
smaller weight.


25/39


-----

# **Exponential smoothing**

ğ›¼ (1 âˆ’ğ›¼) (1 âˆ’ğ›¼) [2] (1 âˆ’ğ›¼) [3] (1 âˆ’ğ›¼) [4]

0.9 0.1 0.01 0.001 0.0001

0.5 0.5 0.25 0.125 0.062

0.1 0.9 0.81 0.729 0.6561

Table: Values for ğ›¼ and (1 âˆ’ğ›¼) [ğ‘›]

The speed at which the old observations are â€œforgottenâ€ depends on the
value of ğ›¼. For a value of ğ›¼ close to 1, old observations are quickly
forgotten, whereas for ğ›¼ close to 0, this goes less fast.

26/39


-----

# **Example**

Figure: Single exponential smoothing with ğ›¼= 0.1, 0.5

27/39


-----

# **Forecasting**

As a forecast for time ğ‘¡+ ğ‘š (ğ‘š time units in the â€œfutureâ€), we always take
the last estimate of the level:

ğ¹(ğ‘¡+ ğ‘š) = ğ‘‹ ğ‘¡

28/39


-----

# **Double exponential smoothing**

Basic exponential smoothing does not work well if there is a trend in the
data

Figure: Exponential smoothing with a trend: the errors keep getting bigger


-----

# **Double exponential smoothing**

We add an additional term to model the trend. We use ğ‘ for the
ğ‘¡
estimation of the trend at time ğ‘¡> 1:

ğ‘‹ ğ‘¡ = ğ›¼ğ‘¥ ğ‘¡ + (1 âˆ’ğ›¼)(ğ‘‹ ğ‘¡âˆ’1 + ğ‘ ğ‘¡âˆ’1 )

ğ‘ ğ‘¡ = ğ›½(ğ‘‹ ğ‘¡ âˆ’ğ‘‹ ğ‘¡âˆ’1 ) + (1 âˆ’ğ›½)ğ‘ ğ‘¡âˆ’1

with 0 < ğ›¼< 1 and 0 < ğ›½< 1

  - ğ‘ ğ‘¡ is an estimate for the slope of the trend line

   - Added to the first equation to ensure that the trend is followed

  - ğ‘‹ ğ‘¡ âˆ’ğ‘‹ ğ‘¡âˆ’1 is positive or negative, this corresponds to an
increasing/decreasing trend

30/39


-----

# **Double exponential smoothing**

Again, there are different options for selecting the initial values:

ğ‘‹
1 = ğ‘¥ 1

ğ‘
1 = ğ‘¥ 2 âˆ’ğ‘¥ 1

ğ‘
1 = [1]

3 [[(ğ‘¥] [2] [ âˆ’ğ‘¥] [1] [) + (ğ‘¥] [1] [ âˆ’ğ‘¥] [2] [) + (ğ‘¥] [4] [ âˆ’ğ‘¥] [3] [)]]

ğ‘¥ âˆ’ğ‘¥
ğ‘ ğ‘› 1
1 =

ğ‘›âˆ’1

31/39


-----

# **Predicting (forecasting)**

To make a prediction (forecast) ğ¹(ğ‘¡+ 1) for time ğ‘¡+ 1 we use:

ğ¹(ğ‘¡+ 1) = ğ‘‹ ğ‘¡ + ğ‘ ğ‘¡

or in general for time ğ‘¡+ ğ‘š:

ğ¹(ğ‘¡+ ğ‘š) = ğ‘‹ ğ‘¡ + ğ‘šğ‘ ğ‘¡

32/39


-----

# **Example**

**Comparison of Single/Double Exponential Smoothing forecasts**

33/39


-----

# **Triple exponential smoothing**

Some time series have recurring (seasonal) patterns, e.g.

34/39


-----

# **Triple exponential smoothing**

**Or Holt-Winterâ€™s Method**

Notation:

   - ğ¿: length of the seasonal cycle (number of time units)

  - ğ‘ : term that models the seasonal variations
ğ‘¡

  - ğ›¾ (gamma): smoothing factor for the seasonal variation

ğ‘¥
ğ‘¡
ğ‘‹ ğ‘¡ = ğ›¼ + (1 âˆ’ğ›¼)(ğ‘‹ ğ‘¡âˆ’1 + ğ‘ ğ‘¡âˆ’1 ) Smoothing
ğ‘
ğ‘¡âˆ’ğ¿

ğ‘ ğ‘¡ = ğ›½(ğ‘‹ ğ‘¡ âˆ’ğ‘‹ ğ‘¡âˆ’1 ) + (1 âˆ’ğ›½)ğ‘ ğ‘¡âˆ’1 Trend smoothing

ğ‘¥
ğ‘¡
ğ‘ ğ‘¡ = ğ›¾ ğ‘‹ + (1 âˆ’ğ›¾)ğ‘ ğ‘¡âˆ’ğ¿ Seasonal smoothing
ğ‘¡

35/39


-----

# **Triple exponential smoothing**

Prediction at time ğ‘¡+ ğ‘š:

ğ¹ ğ‘¡+ğ‘š = (ğ‘‹ ğ‘¡ + ğ‘šğ‘ ğ‘¡ )ğ‘ ğ‘¡âˆ’ğ¿+ğ‘š

36/39


-----

# **Example**

37/39


-----

# **Quality of a time series model**

38/39


-----

# **Quality of a time series model**

Compare forecast results with actual observations, when they become
available:

   - Mean absolute error: ğ‘€ğ´ğ¸= ğ‘š [1] [âˆ‘] ğ‘–=ğ‘¡+1 [ğ‘¡+ğ‘š] [|ğ‘¥] ğ‘– [âˆ’ğ¹] ğ‘– [|]

   - Mean squared error ğ‘€ğ‘†ğ¸= ğ‘š [1] [âˆ‘] ğ‘–=ğ‘¡+1 [ğ‘¡+ğ‘š] [(ğ‘¥] ğ‘– [âˆ’ğ¹] ğ‘– [)] [2]

If square root of MSE is well below standard deviation over all
observations, you have a good model!

39/39


-----

