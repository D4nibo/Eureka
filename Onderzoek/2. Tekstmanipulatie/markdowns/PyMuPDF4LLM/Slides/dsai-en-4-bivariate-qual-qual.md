# **Module 4. Bivariate analysis:** **qualitative variables**
### **Data Science**

**Sabine De Vreese** **Lieven Smits** **Pieter Van Der Helst** **Bert Van Vreckem**

**2024â€“2025**


1/43


-----

# **Contents**

Bivariate analysis

Contingency tables

The chi-squared statistic
CramÃ©râ€™s V

Chi-squared test for independence

Goodness-of-fit test

Testing procedure for goodness of fit test

Standardized residuals

Cochranâ€™s rules

2/43


-----

# **Learning goals**

   - Dependent/independent variable

   - Apply suitable analysis techniques for each combination of
measurement levels

   - Contingency tables and CramÃ©râ€™s ğ‘‰

   - Visualization

3/43


-----

# **Bivariate analysis: overview**

**Independent** **Dependent** **Test/Metric**

Qualitative Qualitative ğœ’ [2] -test
CramÃ©râ€™s ğ‘‰

Qualitative Quantitative two-sample ğ‘¡-test
Cohenâ€™s ğ‘‘

â€”
Quantitative Quantitative
Regression, correlation

4/43


-----

# **Bivariate analysis**


5/43


-----

# **Bivariate analysis**

   - â€¦is determining whether there is an association between two
stochastic variables (ğ‘‹ and ğ‘Œ).

   - **Association** = you can predict (to some extent) the value of ğ‘Œ from
the value of ğ‘‹

   - ğ‘‹ â€” Independent variable

   - ğ‘Œ â€” Dependent variable

   - **Important!** Finding an association does **NOT** imply a causal relation!

6/43


-----

# **Example research questions**

   - Is there a difference in taste preference between two beverage
brands?

   - Is there a difference in spending at the campus restaurant between
students and staff?

   - Do smokers die more often of lung cancer than non-smokers?

   - Do men and women have a different opinion on a survey question?

   - â€¦

We will use data/rlanders.csv from the Github repo for lab
assignments to explore the last question.

7/43


-----

# **Contingency tables**


8/43


-----

# **Contingency tables**

**(also: crosstab)**

See Python example code in demo-4.01-chi-squared.ipynb

**Gender** **Female** **Male**

**Survey**

Strongly disagree 0 4
Disagree 17 45
Neutral 23 91

Agree 12 53
Strongly agree 0 5

9/43


-----

# **Visualization**

A clustered bar chart


A mosaic plot


-----

# **Marginal totals**

**Gender** **Female** **Male** **Total**

**Survey**

Strongly disagree 0 4 4
Disagree 17 45 62
Neutral 23 91 114

Agree 12 53 65
Strongly agree 0 5 5

**Total** 52 198 250

11/43


-----

# **Expected values**

If there is no difference (association), we expect the same ratios in each
column of the table!

**Gender** **Female** **Male** **Total**

**Survey**

Strongly disagree 0.832 3.168 4
Disagree 12.896 49.104 62
Neutral 23.712 90.288 114

Agree 13.520 51.480 65
Strongly agree 1.040 3.960 5

**Total** 52 198 250

In each cell: (row total Ã— column total) / ğ‘›


-----

# **Measuring dispersion**

How far is the observed value ğ‘œ from the expected ğ‘’?

( ğ‘œâˆ’ğ‘’ ) [2]

ğ‘’

**Gender** **Female** **Male**

**Survey**

Strongly disagree 0.832 0.219
Disagree 1.306 0.343
Neutral 0.021 0.006

Agree 0.171 0.045
Strongly agree 1.040 0.273

13/43


-----

# **The chi-squared statistic**

The sum of all these values is notated:


ğœ’ [2] = âˆ‘
ğ‘–

- ğœ’ is the Greek letter *chi*


(ğ‘œ ğ‘– âˆ’ğ‘’ ğ‘– ) [2]

â‰ˆ4.255
ğ‘’
ğ‘–



- ğ‘œ ğ‘– = number of observations in the ğ‘–â€™th cell of the contingency table

- ğ‘’ ğ‘– = expected frequency

- Small value â‡’ no association

- Large value â‡’ association


14/43


-----

# When is ğœ’ [2] large enough?

   - 2 Ã— 2-table with ğœ’ [2] = 10

     - Relatively large difference

     - Indicates association

   - 5 Ã— 5-table with ğœ’ [2] = 10

     - Relatively small difference

     - Does NOT indicate association

We need a metric independent of table size!

15/43


-----

# **CramÃ©râ€™s V**

ğ‘‰= âˆš


ğœ’ [2]

ğ‘›(ğ‘˜âˆ’1) [= ] ~~[âˆš]~~


4.255
250(2 âˆ’1) [â‰ˆ0.130]


with ğ‘› the number of observations, ğ‘˜= min(ğ‘›ğ‘¢ğ‘šğ‘…ğ‘œğ‘¤ğ‘ , ğ‘›ğ‘¢ğ‘šğ¶ğ‘œğ‘™ğ‘ )

**CramÃ©râ€™s V** **Interpretation**

â‰ˆ0 no association

â‰ˆ0.1 weak association

â‰ˆ0.25 moderate association

â‰ˆ0.5 strong association
â‰ˆ0.75 very strong association
â‰ˆ1 complete association


16/43


-----

# **Chi-squared test for** **independence**


17/43


-----

# ğœ’ [2] test for independence

   - = Alternative to CramÃ©râ€™s V to investigate association between
qualitative variables.

   - Value of ğœ’ [2] distributed according to the ğœ’ [2] distribution

18/43


-----

# ğœ’ [2] -distribution in Python

Import scipy.stats
For a ğœ’ [2] -distribution with df degrees of freedom:

**Function** **Purpose**

chi2.pdf(x, df=d) Probability density for x
chi2.cdf(x, df=d) Left-tail probability ğ‘ƒ(ğ‘‹< x)
chi2.sf(x, df=d) Right-tail probability ğ‘ƒ(ğ‘‹> x)
chi2.isf(1-p, df=d) p% of observations is expected
to be lower than this value

19/43


-----

# **Test procedure**

   - **Step 1.** Formulate hypotheses:

   - ğ» 0 : there is no association (ğœ’ [2] is â€œsmallâ€)

   - ğ» 1 : there is an association (ğœ’ [2] is â€œlargeâ€)

   - **Step 2.** Choose significance level, e.g. ğ›¼= 0.05

   - **Step 3.** Calculate the test statistic, ğœ’ [2] = 4.255

20/43


-----

# **Test procedure (cont.)**

   - **Step 4.** Use ğ‘‘ğ‘“= (ğ‘›ğ‘¢ğ‘šğ‘…ğ‘œğ‘¤âˆ’1) Ã— (ğ‘›ğ‘¢ğ‘šğ¶ğ‘œğ‘™âˆ’1) and either:

     - Determine critical value ğ‘” so ğ‘ƒ(ğœ’ [2]     - ğ‘”) = ğ›¼

     - Calculate the ğ‘-value

   - **Step 5.** Draw conclusion:

    - ğœ’ [2] < ğ‘”: do not reject ğ» 0 ; ğœ’ [2]    - ğ‘”: reject ğ» 0

     - ğ‘> ğ›¼: do not reject ğ» 0 ; ğ‘< ğ›¼: reject ğ» 0

21/43


-----

# **Example (Gender vs Survey)**

   - g = stats.chi2.isf(0.05, df=4) (result: 9.4877)

   - p = stats.chi2.sf(4.2555, df=4) (result: 0.3725)

**Conclusion** : we do not reject the null hypothesis. Differences between
expected and observed values are not significantly large.
We found no association between variables *Gender* and *Survey*


-----

# **Test for independence in Python**

SciPy has a function to calculate ğœ’ [2] and ğ‘-value from a contingency table:

3

23/43


-----

# **Goodness-of-fit test**


24/43


-----

# **Goodness-of-fit test**

The ğœ’ [2] test can also be used to determine whether a sample is
**representative** for the population.




25/43


-----

# **Example**

26/43


**Type** **# sample** **# population**

Mutant 127 35%

Human 75 17%

Alien 98 23%

God 27 8%

Demon 73 17%

**Total** 400 100%


-----

# **Example**

Is the distribution of the sample (ğ‘›= 400) representative for the full
population (all superheroes)?

   - What numbers would you *expect* if the sample is representative?

   - How large are the differences from the *observed* numbers?

     - small â‡’ distribution is representative

     - large â‡’ distribution is **not** representative

27/43


-----

# **Example**

Is the distribution of the sample (ğ‘›= 400) representative for the full
population (all superheroes)?

   - What numbers would you *expect* if the sample is representative?

   - How large are the differences from the *observed* numbers?

     - small â‡’ distribution is representative

     - large â‡’ distribution is **not** representative

Can you see the link with contingency tables and Cramerâ€™s V?

27/43


-----

# **Goodness of fit test**

   - Exactly representative â‡’ 35% of superheroes in the sample is a

mutant

   - The expected number therefore is ğ‘’= 0.35 Ã— 400 = 140.

Therefore:

ğ‘’= ğ‘›Ã— ğœ‹

If the differences ğ‘œâˆ’ğ‘’ are relatively small they can be attributed to
random sampling errors.

28/43


-----

# **Goodness of fit test**

Consider ğœ’ [2] :


(ğ‘œ ğ‘– âˆ’ğ‘’ ğ‘– ) [2]

ğ‘’
ğ‘–


ğœ’ [2] =


ğ‘›
âˆ‘
ğ‘–=1


Draw a conclusion based on the value of ğœ’ [2] :

 - small â‡’ distribution is representative

 - large â‡’ distribution is **not** representative

ğœ’ [2] measures the degree of conflict with the null hypothesis


29/43


-----

# **Goodness of fit test**

( ğ‘œâˆ’ğ‘’ ) [2]
**Superhero type** ğ‘œ ğœ‹ ğ‘’

ğ‘’

Mutant 127 35% 140 1.21

Human 75 17% 68 0.72

Alien 98 23% 92 0.39

God 27 8% 32 0.78

Demon 73 17% 68 0.37

ğœ’ [2] = 3.47

30/43


-----

# **Goodness of fit test**

   - The test statistic ğœ’ [2] follows the ğœ’ [2] distribution.

   - Critical value ğ‘” from the ğœ’ [2] distribution: this is dependent on the
number of degrees of freedom (ğ‘‘ğ‘“). In general:

ğ‘‘ğ‘“= ğ‘˜âˆ’1

with ğ‘˜ the number of categories.

   - The critical value ğ‘” for a given significance level ğ›¼ and number of
degrees of freedom ğ‘‘ğ‘“ can be calculated in Python using the
function isf().

ğ‘ƒ(ğœ’ [2] < ğ‘”) = 1 âˆ’ğ›¼

31/43


-----

# **Goodness of fit test**

**Testing Procedure**

1. **Formulate hypotheses**

   - ğ» 0 : sample is representative for the population

   - ğ» 1 : sample is not representative for the population

2. **Choose significance level** : ğ›¼= 0.05

32/43


-----

# **Goodness of fit test**

**Testing Procedure**

1. **Calculate test statistic** :


(ğ‘œ ğ‘– âˆ’ğ‘’ ğ‘– ) [2]

ğ‘’
ğ‘–


ğœ’ [2] =


ğ‘›
âˆ‘
ğ‘–=1


1.1 **Critical area** : Calculate ğ‘” so that ğ‘ƒ(ğœ’ [2] < ğ‘”) = 1 âˆ’ğ›¼
1.2 **Probability value** : Calculate ğ‘= 1 âˆ’ğ‘ƒ(ğ‘‹< ğœ’ [2] )
2. Conclusion (the test is always right-tailed):

2.1 ğœ’ [2] < ğ‘”â‡’ do not reject ğ» 0, ğœ’ [2]   - ğ‘”â‡’ reject ğ» 0
2.2 ğ‘> ğ›¼â‡’ do not reject ğ» 0, ğ‘< ğ›¼â‡’ reject ğ» 0


33/43


-----

# **Example**

   - g = stats.chi2.isf(0.05, df=4) (result: 9.4877)

   - p = stats.chi2.sf(3.4679, df=4) (result: 0.4828)

**Conclusion.** ğœ’ [2] â‰ˆ3.47 < ğ‘”â‰ˆ9.4877, so we donâ€™t reject the null hypothesis.
This sample is representative for the population.

34/43


-----

# **Goodness-of-fit test in Python**

5

35/43


-----

# **Standardized residuals**


36/43


-----

# **Example: families**

Consider all families with exactly 5 children in a given community.


-----

# **Example: families**

Consider all families with exactly 5 children in a given community. When
we look at the number of boys/girls, there are 6 possible combinations:

1. 5 boys

2. 4 boys, 1 girl

3. 3 boys, 2 girls

4. 2 boys, 3 girls

5. 1 boy, 4 girls

6. 5 girls

A survey was conducted regarding 1022 families with exactly 5 children

Are the observed numbers in the 6 classes representative for a
population in which the probability of having a boy is equal to the
probability of having a girl, or more concrete 0.5?


-----

# **Example**

38/43


i 0 1 2 3 4 5

ğ‘œ 58 149 305 303 162 45
ğ‘–


-----

# **Example**

i 0 1 2 3 4 5

ğ‘œ 58 149 305 303 162 45
ğ‘–

If the assumption is true, the probability ğœ‹ ğ‘– to have ğ‘– boys is determined
by a binomial distribution with parameters ğ‘›= 5 and ğ‘= 0.5. For example,
the probability to have 2 boys out of 5 children is equal to:

(0.5) [2] Ã— (1 âˆ’0.5) [5âˆ’2]
Ã— (2 [5][)]

In general (you donâ€™t have to know why):

5!
ğœ‹
ğ‘– = ( [5] ğ‘– [) Ã— 0.5] [ğ‘–] [Ã— 0.5] [5âˆ’ğ‘–] [=] ğ‘–!(5 âˆ’ğ‘–)! [Ã— 0.5] [ğ‘–]

38/43


-----

# **Example**

ğ‘– 0 1 2 3 4 5 Total

ğ‘œ 58 149 305 303 162 45 1022
ğ‘–
ğœ‹ ğ‘– 0,031 0,156 0,313 0,313 0,156 0,031 1
ğ‘’ ğ‘– 31,9 159,7 319,4 319,4 159,7 31,9 1022
( ğ‘œâˆ’ğ‘’ ) [2]

21,268 0,715 0,647 0,840 0,033 5,343 28,846
ğ‘’
ğ‘Ÿ ğ‘– 4,686 -0,921 -0,970 -1,105 0,199 2,348

39/43


-----

# **Example**

1. **Formulate both hypotheses**

   - ğ» 0 : the sample is representative for the population

   - ğ» 1 : the sample is not representative for the population

2. **Determine** ğ›¼ **and** ğ‘›: ğ›¼= 0.01 and ğ‘›= 1022.

3. **Value of the test statistic in the sample** :


(ğ‘œ ğ‘– âˆ’ğ‘’ ğ‘– ) [2]

â‰ˆ28.846
ğ‘’
ğ‘–


ğœ’ [2] =


ğ‘›
âˆ‘
ğ‘–=1


4. **Calculate and plot critical area** : The critical value is 15.0863. Our test
statistic is inside the critical area, so we can reject ğ» 0 .


40/43


-----

# **Standardized Residuals**




ğ‘œ âˆ’ğ‘›ğœ‹
ğ‘– ğ‘–
ğ‘Ÿ =
ğ‘–

~~âˆš~~ [ğ‘›ğœ‹] ğ‘– [(1 âˆ’ğœ‹] ğ‘– [)]

 - ğ‘Ÿ ğ‘– âˆˆ[âˆ’2, 2] â‡’ â€œacceptableâ€ values

 - ğ‘Ÿ ğ‘– < âˆ’2 â‡’ underrepresented

 - ğ‘Ÿ ğ‘– - 2 â‡’ overrepresented

**Conclusion:** families in which all children are of the same gender are
overrepresented.


-----

# **Cochranâ€™s rules**


42/43


-----

# **Conditions**

In order to apply the ğœ’ [2] -test, the following conditions must be met (Rule
of Cochran)

1. For all categories, the expected frequency ğ‘’ must be greater than 1.

2. In a maximum of 20 % of the categories, the expected frequency ğ‘’
may be less than 5.

43/43


-----

